{"cells":[{"cell_type":"markdown","metadata":{"id":"aS4eu_AY66MN"},"source":["# Fine-tuning a model with the Trainer API"]},{"cell_type":"markdown","metadata":{"id":"c_jRpxxd66MQ"},"source":["Install the Transformers and Datasets libraries to run this notebook.\n","\n","https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaForSequenceClassification"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"8aTpCzFNWBof","executionInfo":{"status":"ok","timestamp":1651473145829,"user_tz":-480,"elapsed":537,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4012,"status":"ok","timestamp":1651473149838,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"},"user_tz":-480},"id":"5Sz-ii0d66MR"},"outputs":[],"source":["!pip install -q datasets transformers"]},{"cell_type":"code","source":["train = pd.read_csv('train.tsv',sep='\\t')\n","valid = pd.read_csv('dev.tsv',sep='\\t')\n","test = pd.read_csv('test.tsv',sep='\\t')"],"metadata":{"id":"INda8t3UVtUn","executionInfo":{"status":"ok","timestamp":1651473624460,"user_tz":-480,"elapsed":3,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#from datasets import load_dataset\n","\n","import torch\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\", return_tensors=\"pt\")\n","model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")"],"metadata":{"id":"vozxtqqT9L2O","executionInfo":{"status":"ok","timestamp":1651473702474,"user_tz":-480,"elapsed":9694,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#tokenize dataset\n","def tokenize(t):\n","  return tokenizer(t, truncation=True, max_length=512, padding='max_length',return_tensors = \"pt\")\n","def logits_(inputs):\n","  logits = model(**inputs).logits\n","  return logits\n","def id(logits):\n","  predicted_class_id =  logits.argmax().item()\n","  return model.config.id2label[predicted_class_id]\n","\n","def tokenize_df(df):\n","\n","  tokens = df['comment_text'].map(tokenize)\n","  logits = tokens.map(logits_)\n","  predicted_class_id = logits.map(id)\n","  df[\"predicted_output\"] = predicted_class_id\n","  return df\n","\n","  #df[\"predicted_output\"] = model.config.id2label[predicted_class_id]\n","  #return df"],"metadata":{"id":"07nPBkqaWGkx","executionInfo":{"status":"ok","timestamp":1651473704028,"user_tz":-480,"elapsed":6,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train = train[:20]\n","valid = valid[:1]"],"metadata":{"id":"0i50GH-w9YhS","executionInfo":{"status":"ok","timestamp":1651473704028,"user_tz":-480,"elapsed":5,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["z = tokenize_df(train)"],"metadata":{"id":"fPmO3UEb8Icr","executionInfo":{"status":"ok","timestamp":1651473745511,"user_tz":-480,"elapsed":41487,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"LdfspnNLa1ft","executionInfo":{"status":"ok","timestamp":1651473745515,"user_tz":-480,"elapsed":22,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"4e122d9c-d7e1-4aed-af7e-013e34b9e7b3"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         comment_text  label predicted_output\n","0   one of the more influential works of the ` kor...      1         optimism\n","1                                 incurably romantic       1         optimism\n","2   and your reward will be a thoughtful , emotion...      1         optimism\n","3                to creep the living hell out of you       0              joy\n","4                                in this flat effort       0              joy\n","5   hold our interest , but its just not a thrilli...      0          sadness\n","6                                       irritatingly       0              joy\n","7   the last time i saw worse stunt editing or che...      0              joy\n","8   everything -- even life on an aircraft carrier...      0          sadness\n","9                                ` ron seal the deal       1         optimism\n","10  the most excruciating 86 minutes one might sit...      0              joy\n","11                          traditionally structured       1          sadness\n","12                         incapable of being boring       1          sadness\n","13  sugary sentiment and withholds delivery on the...      0          sadness\n","14  , it 's a rather listless amble down the middl...      0              joy\n","15                                       comic skill       1         optimism\n","16  the things this movie tries to get the audienc...      0              joy\n","17                     the acting is just fine , but       1         optimism\n","18  is all but washed away by sumptuous ocean visu...      1         optimism\n","19                animated filmmaking since old walt       1         optimism"],"text/html":["\n","  <div id=\"df-a3117b51-a74f-474e-bdf8-85b2d44ed1e7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>label</th>\n","      <th>predicted_output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one of the more influential works of the ` kor...</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>incurably romantic</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and your reward will be a thoughtful , emotion...</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>to creep the living hell out of you</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>in this flat effort</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>hold our interest , but its just not a thrilli...</td>\n","      <td>0</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>irritatingly</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>the last time i saw worse stunt editing or che...</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>everything -- even life on an aircraft carrier...</td>\n","      <td>0</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>` ron seal the deal</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>the most excruciating 86 minutes one might sit...</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>traditionally structured</td>\n","      <td>1</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>incapable of being boring</td>\n","      <td>1</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>sugary sentiment and withholds delivery on the...</td>\n","      <td>0</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>, it 's a rather listless amble down the middl...</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>comic skill</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>the things this movie tries to get the audienc...</td>\n","      <td>0</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>the acting is just fine , but</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>is all but washed away by sumptuous ocean visu...</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>animated filmmaking since old walt</td>\n","      <td>1</td>\n","      <td>optimism</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3117b51-a74f-474e-bdf8-85b2d44ed1e7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a3117b51-a74f-474e-bdf8-85b2d44ed1e7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a3117b51-a74f-474e-bdf8-85b2d44ed1e7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"yF4XO3aYgNo6","executionInfo":{"status":"error","timestamp":1651473746661,"user_tz":-480,"elapsed":7,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"10438185-48a0-4e6d-af30-c07593e2de4e"},"execution_count":26,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-434f80264abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mㅋ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ᄏ' is not defined"]}]},{"cell_type":"code","source":["tokenize_df(valid)"],"metadata":{"id":"_5FMaPK_8TAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n","\n","logits = model(**inputs).logits\n","\n","predicted_class_id = logits.argmax().item()\n","model.config.id2label[predicted_class_id]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"qYxH6nHe6Rz5","executionInfo":{"status":"ok","timestamp":1651463917824,"user_tz":-480,"elapsed":493,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"b24d7a50-c8b7-4b04-ed24-a2ea922e89b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'optimism'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#from datasets import load_dataset\n","\n","import torch\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\", return_tensors=\"pt\")\n","model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n","\n","#tokenize dataset\n","def tokenize(t):\n","  return tokenizer(t, truncation=True, max_length=512, padding='max_length',return_tensors = \"pt\")\n","\n","def tokenize_df(df):\n","\n","  tokens = df['comment_text'].map(tokenize)\n","  df['input_ids'] = [x['input_ids'] for x in tokens]\n","  df['attention_mask'] = [x['attention_mask'] for x in tokens]\n","  \n","  df\n","\n","  df[\"predicted_output\"] = \n","  return df"],"metadata":{"id":"_D_wsvWE7zDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = tokenize_df(train)\n","valid = tokenize_df(valid)\n","test = tokenize_df(test)"],"metadata":{"id":"BG_KI7kcW2ZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qZiBhvE66MS"},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gY8BpfJ066MS"},"outputs":[],"source":["from transformers import TrainingArguments\n","training_args = TrainingArguments(\"test-trainer\")"]},{"cell_type":"code","source":["import tempfile\n","import pathlib\n","import pyarrow as pa\n","import pyarrow.parquet as pq"],"metadata":{"id":"fT1GLspHXRYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import datasets\n","from torch.utils.data import DataLoader, Dataset\n","table_train = pa.table({'labels': (list(train[\"label\"])), 'input_ids':list(train[\"input_ids\"]), 'attention_mask':list(train[\"attention_mask\"])})\n","table_validate = pa.table({'labels': list(valid[\"label\"]),'input_ids':list(valid[\"input_ids\"]), 'attention_mask':list(valid[\"attention_mask\"])})\n","table_test = pa.table({'labels': list(test[\"label\"]),'input_ids':list(test[\"input_ids\"]), 'attention_mask':list(test[\"attention_mask\"])})\n","\n","#training = datasets.DatasetDict({\"labels\":list(train_df[\"labels\"]), \"text\": list(train_df[\"text\"])})\n","training = datasets.Dataset(table_train)\n","valid = datasets.Dataset(table_validate)\n","test = datasets.Dataset(table_test)\n","\n","MyDataset = datasets.DatasetDict({\"train\":training,\"validation\":valid, \"test\" : test})"],"metadata":{"id":"Y1oGGC23Xa86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MyDataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBI-s8HGXfbH","executionInfo":{"status":"ok","timestamp":1651463561907,"user_tz":-480,"elapsed":8,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"f1f29bd2-fee1-418e-93b6-c0d1df70dbab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'input_ids', 'attention_mask'],\n","        num_rows: 55673\n","    })\n","    validation: Dataset({\n","        features: ['labels', 'input_ids', 'attention_mask'],\n","        num_rows: 3347\n","    })\n","    test: Dataset({\n","        features: ['labels', 'input_ids', 'attention_mask'],\n","        num_rows: 872\n","    })\n","})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eegbxS9wE006"},"outputs":[],"source":["x = MyDataset[\"train\"]\n","train_small = x.shuffle(seed=1002).select([i for i in range(2000)])\n","y = MyDataset[\"validation\"]\n","valid_small = y.select([i for i in list(range(100))])"]},{"cell_type":"code","source":["train_small"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hddQin1zcvkQ","executionInfo":{"status":"ok","timestamp":1651463577593,"user_tz":-480,"elapsed":5,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"70ef797b-4568-4b98-a40b-406fc21ef9bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 2000\n","})"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["valid_small"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6kANEOr5ml9","executionInfo":{"status":"ok","timestamp":1651463586338,"user_tz":-480,"elapsed":4,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"7fd39146-fffd-42be-977f-65b30487aa8f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 100\n","})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-vKRc0M66MT"},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=train_small,\n","    eval_dataset=valid_small,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":534},"id":"LYumf2SA66MU","executionInfo":{"status":"error","timestamp":1651463704897,"user_tz":-480,"elapsed":337,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"50dc6b7a-6094-4425-aaf8-2769983f35e4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 2000\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 750\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([8])) must be the same as input size (torch.Size([8, 4]))"]}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"c21n0KFqUSK4"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"Vti_B-IiZmJX","executionInfo":{"status":"ok","timestamp":1651458989831,"user_tz":-480,"elapsed":71401,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"04097953-ab1a-4ec8-92a0-a2c7980734cf"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 872\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [109/109 01:10]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(872, 2) (872,)\n"]}],"source":["predictions = trainer.predict(MyDataset[\"test\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXJGJNkcZmJY"},"outputs":[],"source":["preds = np.argmax(predictions.predictions, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LC97zS3nSCzT"},"outputs":[],"source":["gt = np.array(MyDataset[\"test\"][\"labels\"])#[:25])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qruogaipSCeW","executionInfo":{"status":"ok","timestamp":1651458989834,"user_tz":-480,"elapsed":23,"user":{"displayName":"Sun Bin Mun","userId":"11452487959529512770"}},"outputId":"caa5a1a4-58cb-48f7-ffaa-5d4b646fa6d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy is 0.8922018348623854\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.86      0.89       428\n","           1       0.87      0.93      0.90       444\n","\n","    accuracy                           0.89       872\n","   macro avg       0.89      0.89      0.89       872\n","weighted avg       0.89      0.89      0.89       872\n","\n","\n","\n","\n","[[367  61]\n"," [ 33 411]]\n"]}],"source":["import sklearn\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"Validation Accuracy is\",sklearn.metrics.accuracy_score(gt,preds))\n","\n","print(classification_report(gt, preds))\n","print(\"\\n\\n\")\n","print(confusion_matrix(gt, preds))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"RoBERTa (Trainer API)","provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb","timestamp":1651212280983}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}